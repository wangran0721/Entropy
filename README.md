# Entropy
一个关于信息熵的小实验：
前几天读了吴老师的《数学之美》的第六章，关于【同样长度的书，所含信息量可以相差很多】这句话，做了一个小实验。
一：
同语义下中文词汇信息熵和英文词汇信息熵大小比较：
![‘做’所占的比特]
![‘make’所占的比特]
二：
用python脚本在一篇文档中写入500000个“啪”字和500000个随机字符
通过比特大小来查看信息量大小。
![500000个“啪”字所占的比特]
![500000个随机字符所占的比特]
